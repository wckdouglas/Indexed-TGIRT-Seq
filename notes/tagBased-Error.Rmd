---
title: "Tag-based Error correction"
author: "Dougals Wu"
date: "December 1, 2015"
output: html_document
---

This is a note for myself on the tag-based error correction program that I coded up. 

# Grouping

For a given read 1, the first 13 bases is the index as below.

<center>
[GGAAGAGCACACG] TCT GAA CTC CAG TCA CAC TGA TAT CTC GTA TGC CGT CTT CTG CTT GAA AAA AAA AAGG GGG G
</center>

Reads with same index are grouped together in a dictionary (python).


# Concensus base

For a cluster of reads (group), bases at a single position were extracted, concensus base was predicted using maximum likelihood.

For a give position, assume the bases A, C, T, G are observed $j, k, l, m$ times respectively.  The likelihood of the concensus base is A would be computed as:

\[
L(base = A|jA, kC, lT, mG) = P(jA, kC, lT, mG|base=A) = \prod_{b_i \in (\text{all bases})}P(b_i|base=A)
\]

\[
P(jA, kC, lT, mG|base=A) = P(A|base=A)^{j} \times P(C|base=A)^{k} \times P(T|base=A)^{l} \times P(G|base=A)^{m}
\]

And sequencing error was estimated at 0.01.

\[
P(jA, kC, lT, mG|base=A) = (1-0.01)^{j} \times 0.01^{k} \times 0.01^{l} \times 0.01^{m}
\]

Likelihood is calculated for all four base 

\[
\hat{\theta} \in \{L(base=A|jA,kC,lT,mG),L(base=T|jA,kC,lT,mG),L(base=C|jA,kC,lT,mG),L(base=G|jA,kC,lT,mG)\}
\]

likelihood ratio test was performed by:
\[
log(\Lambda) = log(\frac{max(\hat{\theta})}{\sum \hat{\theta} - max(\hat{\theta)}})
\]

If the $log(\Lambda)$ is greater than some threshold, the concensus base is determined to be the base that has maximum likelihood.

  

# log likelihood ratio threshold

To choose the optimal cut off for likelihood ratio, 10000 positions were simulated having coverages from 4-80 reads, and errors are introduced by possion model with the sequencing error $(\lambda = 0.01)$. $log(\Lambda)$ was calculated from each points and plotted as below with respect to coverage:

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(cowplot)

seqErr <- 0.03
cov <- sample(4:80,10000,replace=T)
df <- data_frame(cov) %>%
#	mutate(mismatch = sapply(cov,function(a) rbinom(1,a,seqErr))) %>%
	mutate(mismatch = rpois(cov,0.01)) %>%
	mutate(match = cov - mismatch) %>%
	mutate(correctLikelihood = 0.99 ^ match * 0.01 ^ mismatch) %>%
	mutate(incorrectLikelihood = 0.99 ^ mismatch * 0.01 ^ match) %>%
	mutate(likelihoodRatio = correctLikelihood/incorrectLikelihood) %>%
	mutate(loglikelihoodRatio = log(correctLikelihood)-log(incorrectLikelihood)) %>%
	mutate(loglikelihoodRatio = ifelse(loglikelihoodRatio<0,0,loglikelihoodRatio)) %>%
    mutate(newParam = loglikelihoodRatio/cov) %>%
	tbl_df

p3 <- ggplot(data=df,aes(y=loglikelihoodRatio,x=cov)) +
	geom_smooth(method='lm') +
	geom_point() 

p3
```

\newpage
It can be seen that loglikeliihoodRatio is porportion to coverage, so a threshold must be chosen with respect to coverage. Plotting a histogram of $\frac{loglikelihoodRatio}{coverage}$, a threshold was chosen around 4.55.

```{r echo=FALSE, message=FALSE, warning=FALSE}
p4 <- ggplot(data=df,aes(x=newParam)) +
	geom_bar(binwidth=0.01) +
    scale_y_log10()+
	scale_x_continuous(breaks=seq(0,5,0.1)) +
	theme(axis.text.x = element_text(angle=90,hjust=1,vjust=0.5))
p4
```